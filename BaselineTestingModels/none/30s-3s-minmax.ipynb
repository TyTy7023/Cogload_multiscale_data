{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":9448170,"datasetId":5720188,"databundleVersionId":9654618,"isSourceIdPinned":false}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **I/ setUpEnvironment**","metadata":{}},{"cell_type":"code","source":"#to access files and folders\nimport os\n#data analysis and manipulation library\nimport pandas as pd\n#math operations for multi-dimensional arrays and matrices\nimport numpy as np\n#visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set() #use a specific color theme\n\nimport warnings\nwarnings.simplefilter(\"ignore\")#ignore warnings during execution\n\n#Using model\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report, accuracy_score,log_loss\nfrom sklearn.metrics import confusion_matrix\n\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-08T00:13:45.505077Z","iopub.execute_input":"2024-10-08T00:13:45.505504Z","iopub.status.idle":"2024-10-08T00:13:48.418017Z","shell.execute_reply.started":"2024-10-08T00:13:45.505465Z","shell.execute_reply":"2024-10-08T00:13:48.417072Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# **II/ readData**","metadata":{}},{"cell_type":"code","source":"#read the data\ndata_folder_path = '/kaggle/input/cognitiveload/UBIcomp2020/last_30s_segments/'\n#read the data\nprint('Reading data')\nlabel_df = pd.read_excel(data_folder_path+'labels.xlsx',index_col=0)\ntemp_df= pd.read_excel(data_folder_path+'temp.xlsx',index_col=0)\nhr_df= pd.read_excel(data_folder_path+'hr.xlsx',index_col=0)\ngsr_df = pd.read_excel(data_folder_path+'gsr.xlsx',index_col=0)\nrr_df= pd.read_excel(data_folder_path+'rr.xlsx',index_col=0)\nprint('Done')\n\n#check 30-second segments\nprint(\"Data shapes:\")\nprint('Labels',label_df.shape)\nprint('Temperature',temp_df.shape)\nprint('Heartrate',hr_df.shape)\nprint('GSR',gsr_df.shape)\nprint('RR',rr_df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T00:13:48.419737Z","iopub.execute_input":"2024-10-08T00:13:48.420223Z","iopub.status.idle":"2024-10-08T00:13:50.591806Z","shell.execute_reply.started":"2024-10-08T00:13:48.420185Z","shell.execute_reply":"2024-10-08T00:13:50.590651Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Reading data\nDone\nData shapes:\nLabels (825, 21)\nTemperature (825, 30)\nHeartrate (825, 30)\nGSR (825, 30)\nRR (825, 30)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **III/ SMA**","metadata":{}},{"cell_type":"code","source":"window = 3\n#apply moving average to each 30-second segment separately\ntemp_df = temp_df.rolling(window,axis=1).mean()\nhr_df = hr_df.rolling(window,axis=1).mean()\ngsr_df = gsr_df.rolling(window,axis=1).mean()\nrr_df = rr_df.rolling(window,axis=1).mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **IV/ statisticalFeatures**","metadata":{}},{"cell_type":"code","source":"def extract_stat_features(df,data_type=''):\n  stat_features_names = ['mean','std','skew','kurtosis','diff','diff2','q25','q75','qdev','max-min']\n  final_names =  [data_type + '_' + x for x in stat_features_names]\n  features = pd.DataFrame(columns = stat_features_names) #create empty dataframe\n  values = [df.mean(axis=1).values, #mean\n            df.std(axis=1).values,  #standard deviation\n            df.skew(axis=1).values, #skewness\n            df.kurtosis(axis=1).values, #kurtosis\n            df.diff(axis=1).mean(axis=1).values, #mean value of first derivative\n            df.diff(axis=1).diff(axis=1).mean(axis=1).values, #mean value of second derivative\n            df.quantile(0.25,axis=1).values, #25th quantile\n            df.quantile(0.75,axis=1).values,#75th quantile\n            df.quantile(0.75,axis=1).values-df.quantile(0.25,axis=1).values, #quartile deviation\n            df.max(axis=1).values-df.min(axis=1).values] #range\n  values  = np.column_stack(values)\n  return pd.DataFrame(values,columns = final_names)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T00:03:49.474469Z","iopub.execute_input":"2024-10-08T00:03:49.475683Z","iopub.status.idle":"2024-10-08T00:03:49.486248Z","shell.execute_reply.started":"2024-10-08T00:03:49.475629Z","shell.execute_reply":"2024-10-08T00:03:49.485045Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#extract features from heart-rate data\ntemp_stat_features = extract_stat_features(temp_df,'temp')\n\nhr_stat_features = extract_stat_features(hr_df,'hr')\n\ngsr_stat_features = extract_stat_features(gsr_df,'gsr')\n\nrr_stat_features = extract_stat_features(rr_df,'rr')\n\n#merge all statistical features into one table\nstat_feat_all = pd.concat([temp_stat_features,hr_stat_features,gsr_stat_features,rr_stat_features],axis=1)\nstat_feat_all","metadata":{"execution":{"iopub.status.busy":"2024-10-08T00:03:49.732966Z","iopub.execute_input":"2024-10-08T00:03:49.733414Z","iopub.status.idle":"2024-10-08T00:03:49.862832Z","shell.execute_reply.started":"2024-10-08T00:03:49.733363Z","shell.execute_reply":"2024-10-08T00:03:49.861501Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"     temp_mean  temp_std  temp_skew  temp_kurtosis  temp_diff  temp_diff2  \\\n0    34.467000  0.014656  -0.283014      -1.993781   0.001034    0.000000   \n1    34.500000  0.000000   0.000000       0.000000   0.000000    0.000000   \n2    34.544001  0.011156   2.770643       6.626118   0.001379    0.000000   \n3    34.620666  0.002684   4.280921      18.773201   0.000460    0.000238   \n4    35.160000  0.000000   0.000000       0.000000   0.000000    0.000000   \n..         ...       ...        ...            ...        ...         ...   \n820  34.157999  0.017973  -0.917562      -1.151436  -0.001379    0.000000   \n821  34.004667  0.018968   0.581940      -1.708391  -0.001379    0.000000   \n822  33.786001  0.019306   0.429374      -1.878756  -0.001379    0.000000   \n823  34.080557  0.003043   5.477226      30.000000  -0.000575    0.000595   \n824  33.946000  0.024718  -1.324393      -0.137005  -0.002069    0.000000   \n\n      temp_q25   temp_q75  temp_qdev  temp_max-min  ...   rr_mean    rr_std  \\\n0    34.450001  34.480000   0.029999      0.029999  ...  0.875965  0.039381   \n1    34.500000  34.500000   0.000000      0.000000  ...  0.713272  0.129408   \n2    34.540001  34.540001   0.000000      0.040001  ...  0.901683  0.078222   \n3    34.619999  34.619999   0.000000      0.013334  ...  0.883801  0.074364   \n4    35.160000  35.160000   0.000000      0.000000  ...  0.970448  0.024030   \n..         ...        ...        ...           ...  ...       ...       ...   \n820  34.133334  34.169998   0.036664      0.039997  ...  0.830706  0.056278   \n821  33.990002  34.029999   0.039997      0.039997  ...  0.894217  0.076420   \n822  33.770000  33.810001   0.040001      0.040001  ...  0.868868  0.052516   \n823  34.080002  34.080002   0.000000      0.016666  ...  0.758900  0.138672   \n824  33.945000  33.959999   0.014999      0.059998  ...  0.826650  0.060789   \n\n      rr_skew  rr_kurtosis   rr_diff      rr_diff2    rr_q25    rr_q75  \\\n0   -0.111057    -0.147895  0.001716  1.185143e-03  0.854488  0.902881   \n1   -0.486045    -1.099709  0.000763  1.007371e-02  0.598695  0.821304   \n2   -0.712046     0.789044  0.009345 -9.876190e-04  0.875228  0.951275   \n3   -0.197954    -0.157803 -0.003433  2.172762e-03  0.835131  0.922239   \n4    0.156973    -1.345905  0.002479  1.030921e-16  0.951275  0.992755   \n..        ...          ...       ...           ...       ...       ...   \n820 -0.223922    -0.084762  0.006866  1.185143e-03  0.797799  0.868315   \n821  0.024204    -1.293893  0.003051 -4.938095e-03  0.824761  0.960953   \n822  0.600912     0.737710  0.002289 -5.925714e-04  0.836513  0.884907   \n823 -1.354974     2.563826  0.002861  3.950476e-04  0.753553  0.796416   \n824 -0.404944    -0.799312 -0.001716  5.925714e-04  0.779824  0.868315   \n\n      rr_qdev  rr_max-min  \n0    0.048393    0.160389  \n1    0.222609    0.403739  \n2    0.076047    0.331840  \n3    0.087108    0.298656  \n4    0.041480    0.071899  \n..        ...         ...  \n820  0.070516    0.226757  \n821  0.136193    0.271003  \n822  0.048393    0.221227  \n823  0.042863    0.641557  \n824  0.088491    0.210165  \n\n[825 rows x 40 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>temp_mean</th>\n      <th>temp_std</th>\n      <th>temp_skew</th>\n      <th>temp_kurtosis</th>\n      <th>temp_diff</th>\n      <th>temp_diff2</th>\n      <th>temp_q25</th>\n      <th>temp_q75</th>\n      <th>temp_qdev</th>\n      <th>temp_max-min</th>\n      <th>...</th>\n      <th>rr_mean</th>\n      <th>rr_std</th>\n      <th>rr_skew</th>\n      <th>rr_kurtosis</th>\n      <th>rr_diff</th>\n      <th>rr_diff2</th>\n      <th>rr_q25</th>\n      <th>rr_q75</th>\n      <th>rr_qdev</th>\n      <th>rr_max-min</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>34.467000</td>\n      <td>0.014656</td>\n      <td>-0.283014</td>\n      <td>-1.993781</td>\n      <td>0.001034</td>\n      <td>0.000000</td>\n      <td>34.450001</td>\n      <td>34.480000</td>\n      <td>0.029999</td>\n      <td>0.029999</td>\n      <td>...</td>\n      <td>0.875965</td>\n      <td>0.039381</td>\n      <td>-0.111057</td>\n      <td>-0.147895</td>\n      <td>0.001716</td>\n      <td>1.185143e-03</td>\n      <td>0.854488</td>\n      <td>0.902881</td>\n      <td>0.048393</td>\n      <td>0.160389</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>34.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>34.500000</td>\n      <td>34.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.713272</td>\n      <td>0.129408</td>\n      <td>-0.486045</td>\n      <td>-1.099709</td>\n      <td>0.000763</td>\n      <td>1.007371e-02</td>\n      <td>0.598695</td>\n      <td>0.821304</td>\n      <td>0.222609</td>\n      <td>0.403739</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34.544001</td>\n      <td>0.011156</td>\n      <td>2.770643</td>\n      <td>6.626118</td>\n      <td>0.001379</td>\n      <td>0.000000</td>\n      <td>34.540001</td>\n      <td>34.540001</td>\n      <td>0.000000</td>\n      <td>0.040001</td>\n      <td>...</td>\n      <td>0.901683</td>\n      <td>0.078222</td>\n      <td>-0.712046</td>\n      <td>0.789044</td>\n      <td>0.009345</td>\n      <td>-9.876190e-04</td>\n      <td>0.875228</td>\n      <td>0.951275</td>\n      <td>0.076047</td>\n      <td>0.331840</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34.620666</td>\n      <td>0.002684</td>\n      <td>4.280921</td>\n      <td>18.773201</td>\n      <td>0.000460</td>\n      <td>0.000238</td>\n      <td>34.619999</td>\n      <td>34.619999</td>\n      <td>0.000000</td>\n      <td>0.013334</td>\n      <td>...</td>\n      <td>0.883801</td>\n      <td>0.074364</td>\n      <td>-0.197954</td>\n      <td>-0.157803</td>\n      <td>-0.003433</td>\n      <td>2.172762e-03</td>\n      <td>0.835131</td>\n      <td>0.922239</td>\n      <td>0.087108</td>\n      <td>0.298656</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35.160000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>35.160000</td>\n      <td>35.160000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.970448</td>\n      <td>0.024030</td>\n      <td>0.156973</td>\n      <td>-1.345905</td>\n      <td>0.002479</td>\n      <td>1.030921e-16</td>\n      <td>0.951275</td>\n      <td>0.992755</td>\n      <td>0.041480</td>\n      <td>0.071899</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>820</th>\n      <td>34.157999</td>\n      <td>0.017973</td>\n      <td>-0.917562</td>\n      <td>-1.151436</td>\n      <td>-0.001379</td>\n      <td>0.000000</td>\n      <td>34.133334</td>\n      <td>34.169998</td>\n      <td>0.036664</td>\n      <td>0.039997</td>\n      <td>...</td>\n      <td>0.830706</td>\n      <td>0.056278</td>\n      <td>-0.223922</td>\n      <td>-0.084762</td>\n      <td>0.006866</td>\n      <td>1.185143e-03</td>\n      <td>0.797799</td>\n      <td>0.868315</td>\n      <td>0.070516</td>\n      <td>0.226757</td>\n    </tr>\n    <tr>\n      <th>821</th>\n      <td>34.004667</td>\n      <td>0.018968</td>\n      <td>0.581940</td>\n      <td>-1.708391</td>\n      <td>-0.001379</td>\n      <td>0.000000</td>\n      <td>33.990002</td>\n      <td>34.029999</td>\n      <td>0.039997</td>\n      <td>0.039997</td>\n      <td>...</td>\n      <td>0.894217</td>\n      <td>0.076420</td>\n      <td>0.024204</td>\n      <td>-1.293893</td>\n      <td>0.003051</td>\n      <td>-4.938095e-03</td>\n      <td>0.824761</td>\n      <td>0.960953</td>\n      <td>0.136193</td>\n      <td>0.271003</td>\n    </tr>\n    <tr>\n      <th>822</th>\n      <td>33.786001</td>\n      <td>0.019306</td>\n      <td>0.429374</td>\n      <td>-1.878756</td>\n      <td>-0.001379</td>\n      <td>0.000000</td>\n      <td>33.770000</td>\n      <td>33.810001</td>\n      <td>0.040001</td>\n      <td>0.040001</td>\n      <td>...</td>\n      <td>0.868868</td>\n      <td>0.052516</td>\n      <td>0.600912</td>\n      <td>0.737710</td>\n      <td>0.002289</td>\n      <td>-5.925714e-04</td>\n      <td>0.836513</td>\n      <td>0.884907</td>\n      <td>0.048393</td>\n      <td>0.221227</td>\n    </tr>\n    <tr>\n      <th>823</th>\n      <td>34.080557</td>\n      <td>0.003043</td>\n      <td>5.477226</td>\n      <td>30.000000</td>\n      <td>-0.000575</td>\n      <td>0.000595</td>\n      <td>34.080002</td>\n      <td>34.080002</td>\n      <td>0.000000</td>\n      <td>0.016666</td>\n      <td>...</td>\n      <td>0.758900</td>\n      <td>0.138672</td>\n      <td>-1.354974</td>\n      <td>2.563826</td>\n      <td>0.002861</td>\n      <td>3.950476e-04</td>\n      <td>0.753553</td>\n      <td>0.796416</td>\n      <td>0.042863</td>\n      <td>0.641557</td>\n    </tr>\n    <tr>\n      <th>824</th>\n      <td>33.946000</td>\n      <td>0.024718</td>\n      <td>-1.324393</td>\n      <td>-0.137005</td>\n      <td>-0.002069</td>\n      <td>0.000000</td>\n      <td>33.945000</td>\n      <td>33.959999</td>\n      <td>0.014999</td>\n      <td>0.059998</td>\n      <td>...</td>\n      <td>0.826650</td>\n      <td>0.060789</td>\n      <td>-0.404944</td>\n      <td>-0.799312</td>\n      <td>-0.001716</td>\n      <td>5.925714e-04</td>\n      <td>0.779824</td>\n      <td>0.868315</td>\n      <td>0.088491</td>\n      <td>0.210165</td>\n    </tr>\n  </tbody>\n</table>\n<p>825 rows × 40 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_ids = ['3caqi','6frz4','bd47a','f1gjp','iz3x1']\n\ntrain_ids = ['1mpau', '2nxs5', '5gpsc', '7swyk', '8a1ep', 'b7mrd',\n       'c24ur', 'dkhty', 'e4gay', 'ef5rq', 'f3j25', 'hpbxa',\n       'ibvx8', 'iz2ps', 'rc1in', 'tn4vl', 'wjxci', 'yljm5']\n\nX_train = []\ny_train = []\nX_test = []\ny_test = []\nuser_train = []\nuser_test = []\n\nfor user in label_df.user_id.unique():\n    if user in train_ids:\n        user_features = stat_feat_all[label_df.user_id == user]\n        X_train.append(user_features)\n        y = label_df.loc[label_df.user_id == user, 'level'].values\n        \n        # Convert labels (rest,0,1,2) to binary (rest vs task)\n        y[y == 'rest'] = -1\n        y = y.astype(int) + 1\n        y[y > 0] = 1\n        y_train.extend(y)\n        \n        temp = label_df.loc[label_df.user_id==user,'user_id'].values #labels\n        user_train.extend(temp)\n    elif user in test_ids:\n        user_features = stat_feat_all[label_df.user_id == user]\n        X_test.append(user_features)\n        y = label_df.loc[label_df.user_id == user, 'level'].values\n        \n        # Convert labels (rest,0,1,2) to binary (rest vs task)\n        y[y == 'rest'] = -1\n        y = y.astype(int) + 1\n        y[y > 0] = 1\n        y_test.extend(y)\n        \n        temp = label_df.loc[label_df.user_id==user,'user_id'].values #labels\n        user_test.extend(temp)\n\n# Concatenate and convert to DataFrame/NumPy array\nX_train = pd.concat(X_train, ignore_index=True)\ny_train = np.array(y_train)\nX_test = pd.concat(X_test, ignore_index=True)\ny_test = np.array(y_test)\n\nprint('Train data:', X_train.shape, y_train.shape)\nprint('Test data:', X_test.shape, y_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-08T00:03:50.582958Z","iopub.execute_input":"2024-10-08T00:03:50.583438Z","iopub.status.idle":"2024-10-08T00:03:50.657395Z","shell.execute_reply.started":"2024-10-08T00:03:50.583393Z","shell.execute_reply":"2024-10-08T00:03:50.656231Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Train data: (632, 40) (632,)\nTest data: (193, 40) (193,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **IV/ Preprocessing**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\nX_train = pd.DataFrame(X_train)\nX_test = pd.DataFrame(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T00:03:53.001615Z","iopub.execute_input":"2024-10-08T00:03:53.002837Z","iopub.status.idle":"2024-10-08T00:03:53.017934Z","shell.execute_reply.started":"2024-10-08T00:03:53.002784Z","shell.execute_reply":"2024-10-08T00:03:53.016655Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# **V/ featureSelection**","metadata":{}},{"cell_type":"markdown","source":"None","metadata":{}},{"cell_type":"markdown","source":"# **VI/ Experiment**","metadata":{}},{"cell_type":"markdown","source":"# **Logistic Regession**","metadata":{}},{"cell_type":"code","source":"# K-Fold Cross-Validation với 6 folds\nkf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n    \n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}')    \n\n    logreg = LogisticRegression()\n    # Find best parmeter \n    param_grid = {\n        'C': [0.01, 0.1, 1, 10, 100],\n        'penalty': ['l1', 'l2'],        \n        'solver': ['liblinear']         \n    }\n    grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n    \n    y_val_pred = grid_search.predict(X_val_fold)\n    y_pred_prob = grid_search.predict_proba(X_val_fold)\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss = log_loss(y_val_fold, y_pred_prob)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": logreg,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss)\n\n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_lr = best_model.predict(X_test)\ny_pred_lr_proba = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\nlr = accuracy_score(y_test, y_pred_lr)\nconf_matrix = confusion_matrix(y_test, y_pred_lr)\nclass_report = classification_report(y_test, y_pred_lr)\nlr_logloss = log_loss(y_test, y_pred_lr_proba)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {lr}\")\nprint(f\"LOGLOSS: {lr_logloss}\")\n\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_lr)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(logloss_all)\nprint(f\"Accucracy all fold: {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"LogLoss all fold: {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T00:03:55.516746Z","iopub.execute_input":"2024-10-08T00:03:55.517160Z","iopub.status.idle":"2024-10-08T00:04:15.985853Z","shell.execute_reply.started":"2024-10-08T00:03:55.517121Z","shell.execute_reply":"2024-10-08T00:04:15.984997Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"User of train_fold(0) : ['1mpau' '2nxs5' '7swyk' '8a1ep' 'b7mrd' 'c24ur' 'e4gay' 'ef5rq' 'f3j25'\n 'ibvx8' 'iz2ps' 'rc1in' 'tn4vl' 'wjxci' 'yljm5']\nUser of val_fold(0) :['5gpsc' 'dkhty' 'hpbxa']\nFitting 3 folds for each of 10 candidates, totalling 30 fits\nBest parameters found: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n\nUser of train_fold(1) : ['1mpau' '2nxs5' '5gpsc' '7swyk' '8a1ep' 'b7mrd' 'c24ur' 'dkhty' 'ef5rq'\n 'f3j25' 'hpbxa' 'iz2ps' 'rc1in' 'tn4vl' 'wjxci']\nUser of val_fold(1) :['e4gay' 'ibvx8' 'yljm5']\nFitting 3 folds for each of 10 candidates, totalling 30 fits\nBest parameters found: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n\nUser of train_fold(2) : ['1mpau' '2nxs5' '5gpsc' '7swyk' '8a1ep' 'b7mrd' 'c24ur' 'dkhty' 'e4gay'\n 'ef5rq' 'hpbxa' 'ibvx8' 'rc1in' 'wjxci' 'yljm5']\nUser of val_fold(2) :['f3j25' 'iz2ps' 'tn4vl']\nFitting 3 folds for each of 10 candidates, totalling 30 fits\nBest parameters found: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n\nUser of train_fold(3) : ['1mpau' '5gpsc' '7swyk' '8a1ep' 'c24ur' 'dkhty' 'e4gay' 'ef5rq' 'f3j25'\n 'hpbxa' 'ibvx8' 'iz2ps' 'tn4vl' 'wjxci' 'yljm5']\nUser of val_fold(3) :['2nxs5' 'b7mrd' 'rc1in']\nFitting 3 folds for each of 10 candidates, totalling 30 fits\nBest parameters found: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n\nUser of train_fold(4) : ['2nxs5' '5gpsc' '7swyk' 'b7mrd' 'dkhty' 'e4gay' 'ef5rq' 'f3j25' 'hpbxa'\n 'ibvx8' 'iz2ps' 'rc1in' 'tn4vl' 'wjxci' 'yljm5']\nUser of val_fold(4) :['1mpau' '8a1ep' 'c24ur']\nFitting 3 folds for each of 10 candidates, totalling 30 fits\nBest parameters found: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n\nUser of train_fold(5) : ['1mpau' '2nxs5' '5gpsc' '8a1ep' 'b7mrd' 'c24ur' 'dkhty' 'e4gay' 'f3j25'\n 'hpbxa' 'ibvx8' 'iz2ps' 'rc1in' 'tn4vl' 'yljm5']\nUser of val_fold(5) :['7swyk' 'ef5rq' 'wjxci']\nFitting 3 folds for each of 10 candidates, totalling 30 fits\nBest parameters found: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n\nReport:              precision    recall  f1-score   support\n\n           0       0.64      0.63      0.63        95\n           1       0.65      0.65      0.65        98\n\n    accuracy                           0.64       193\n   macro avg       0.64      0.64      0.64       193\nweighted avg       0.64      0.64      0.64       193\n\nACCURACY: 0.6424870466321243\nLOGLOSS: 0.6449991125519394\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Accucracy all fold: [0.58695652 0.6875     0.52678571 0.67592593 0.70833333 0.54464286]\nMean: 0.6216907254044935 ---- Std: 0.07179723665815468\nLogLoss all fold: [0.68774186 0.64130155 0.68272359 0.64909018 0.63006673 0.69047436]\nMean: 0.6635663761561795 ---- Std: 0.024162646303383842\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **LDA**","metadata":{}},{"cell_type":"code","source":"# K-Fold Cross-Validation với 5 folds\nkf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n    \n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}')    \n\n    lda = LinearDiscriminantAnalysis()\n    param_grid = {\n        'solver': ['svd', 'lsqr', 'eigen'],  \n        'shrinkage': [None, 'auto', 0.1, 0.5, 0.9] \n    }\n    grid_search = GridSearchCV(estimator=lda, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n    \n    y_val_pred = grid_search.predict(X_val_fold)\n    y_pred_prob = grid_search.predict_proba(X_val_fold)\n\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss = log_loss(y_val_fold, y_pred_prob)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": lda,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss)\n    \n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_lda = best_model.predict(X_test)\ny_pred_lda_prob = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\nlda = accuracy_score(y_test, y_pred_lda)\nconf_matrix = confusion_matrix(y_test, y_pred_lda)\nclass_report = classification_report(y_test, y_pred_lda)\nlogloss_lda = log_loss(y_test, y_pred_lda_prob)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {lda}\")\nprint(f\"LOGLOSS: {logloss_lda}\")\n\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_lda)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(logloss_all)\nprint(f\"Accucracy All : {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"Logloss All : {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:13:10.317809Z","iopub.execute_input":"2024-10-05T14:13:10.319261Z","iopub.status.idle":"2024-10-05T14:13:13.120735Z","shell.execute_reply.started":"2024-10-05T14:13:10.319203Z","shell.execute_reply":"2024-10-05T14:13:13.119105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **knn**","metadata":{}},{"cell_type":"code","source":"# K-Fold Cross-Validation với 5 folds\nkf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n    \n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}\\n')    \n\n    knn = KNeighborsClassifier()\n    param_grid = {\n        'n_neighbors': [3, 5, 7, 9, 11],        # Số lượng láng giềng k\n        'weights': ['uniform', 'distance'],     # Trọng số: uniform (các điểm đều quan trọng), distance (trọng số theo khoảng cách)\n        'metric': ['euclidean', 'manhattan', 'minkowski']  # Loại khoảng cách: Euclidean, Manhattan hoặc Minkowski\n    }\n    grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n    \n    y_val_pred = grid_search.predict(X_val_fold)\n    y_val_pred_prob = grid_search.predict_proba(X_val_fold)\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss = log_loss(y_val_fold, y_val_pred_prob)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": knn,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss)\n\n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_knn = best_model.predict(X_test)\ny_pred_knn_proba = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\nknn = accuracy_score(y_test, y_pred_knn)\nconf_matrix = confusion_matrix(y_test, y_pred_knn)\nclass_report = classification_report(y_test, y_pred_knn)\nlogloss_knn = log_loss(y_test, y_pred_knn_proba)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {knn}\")\nprint(f\"LOGLOSS: {logloss_knn}\")\n\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_knn)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(logloss_all)\nprint(f\"Accucracy All : {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"Logloss All : {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:13:13.123794Z","iopub.execute_input":"2024-10-05T14:13:13.125207Z","iopub.status.idle":"2024-10-05T14:13:22.781415Z","shell.execute_reply.started":"2024-10-05T14:13:13.125123Z","shell.execute_reply":"2024-10-05T14:13:22.779904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **DecisionTreeClassifier**","metadata":{}},{"cell_type":"code","source":"# K-Fold Cross-Validation với 5 folds\nkf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n    \n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}\\n')    \n\n    cart = DecisionTreeClassifier()\n    param_grid = {\n        'criterion': ['gini', 'entropy'],   # Chỉ số phân chia: Gini hoặc Entropy\n        'max_depth': [None, 10, 20, 30, 40, 50],  # Chiều sâu tối đa của cây\n        'min_samples_split': [2, 10, 20],  # Số mẫu tối thiểu để chia nút\n        'min_samples_leaf': [1, 5, 10],    # Số mẫu tối thiểu tại mỗi nút lá\n        'max_features': [None, 'auto', 'sqrt', 'log2']  # Số lượng đặc trưng được xem xét tại mỗi nút phân chia\n    }\n\n    grid_search = GridSearchCV(estimator=cart, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n  \n    y_val_pred = grid_search.predict(X_val_fold)\n    y_val_pred_prob = grid_search.predict_proba(X_val_fold)\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss = log_loss(y_val_fold, y_val_pred_prob)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": cart,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss)\n\n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_cart = best_model.predict(X_test)\ny_pred_cart_proba = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\ncart = accuracy_score(y_test, y_pred_cart)\nconf_matrix = confusion_matrix(y_test, y_pred_cart)\nclass_report = classification_report(y_test, y_pred_cart)\nlogloss_cart = log_loss(y_test, y_pred_cart_proba)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {cart}\")\nprint(f\"LOGLOSS: {logloss_cart}\")\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_cart)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(logloss_all)\nprint(f\"Accucracy All : {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"Logloss All : {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:13:22.784342Z","iopub.execute_input":"2024-10-05T14:13:22.785505Z","iopub.status.idle":"2024-10-05T14:14:43.492728Z","shell.execute_reply.started":"2024-10-05T14:13:22.785428Z","shell.execute_reply":"2024-10-05T14:14:43.491083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **GaussianNB**","metadata":{}},{"cell_type":"code","source":"# K-Fold Cross-Validation với 5 folds\nkf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n    \n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}\\n')    \n\n    nb = GaussianNB()\n    param_grid = {\n        'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]  # Điều chỉnh biến nhỏ để tăng độ ổn định tính toán\n    }\n\n    grid_search = GridSearchCV(estimator=nb, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n  \n    y_val_pred = grid_search.predict(X_val_fold)\n    y_val_pred_proba = grid_search.predict_proba(X_val_fold)\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss = log_loss(y_val_fold, y_val_pred_proba)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": nb,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss)\n\n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_gnb = best_model.predict(X_test)\ny_pred_gnb_proba = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\ngnb = accuracy_score(y_test, y_pred_gnb)\nconf_matrix = confusion_matrix(y_test, y_pred_gnb)\nclass_report = classification_report(y_test, y_pred_gnb)\nlogloss_gnb = log_loss(y_test, y_pred_gnb_proba)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {gnb}\")\nprint(f\"LOGLOSS: {logloss_gnb}\")\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_gnb)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(logloss_all)\nprint(f\"Accucracy All : {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"Logloss All : {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:14:43.495676Z","iopub.execute_input":"2024-10-05T14:14:43.497217Z","iopub.status.idle":"2024-10-05T14:14:44.675653Z","shell.execute_reply.started":"2024-10-05T14:14:43.497123Z","shell.execute_reply":"2024-10-05T14:14:44.67385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **AdaBoots**","metadata":{}},{"cell_type":"code","source":"# K-Fold Cross-Validation với 5 folds\nkf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n    \n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}\\n')    \n\n    adaboost = AdaBoostClassifier()\n    param_grid = {\n        'n_estimators': [50, 100, 200],  # Số lượng bộ phân loại cơ sở (number of weak learners)\n        'learning_rate': [0.01, 0.1, 1.0],  # Tốc độ học (learning rate)\n    }\n\n    grid_search = GridSearchCV(estimator=adaboost, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n   \n    y_val_pred = grid_search.predict(X_val_fold)\n    y_val_pred_proba = grid_search.predict_proba(X_val_fold)\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss = log_loss(y_val_fold, y_val_pred_proba)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": adaboost,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss)\n\n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_ab = best_model.predict(X_test)\ny_pred_ab_proba = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\nab = accuracy_score(y_test, y_pred_ab)\nconf_matrix = confusion_matrix(y_test, y_pred_ab)\nclass_report = classification_report(y_test, y_pred_ab)\nlogloss_ab = log_loss(y_test, y_pred_ab_proba)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {ab}\")\nprint(f\"LOGLOSS: {logloss_ab}\")\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_ab)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(logloss_all)\nprint(f\"Accucracy All : {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"Logloss All : {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:14:44.678619Z","iopub.execute_input":"2024-10-05T14:14:44.679699Z","iopub.status.idle":"2024-10-05T14:15:51.453165Z","shell.execute_reply.started":"2024-10-05T14:14:44.679623Z","shell.execute_reply":"2024-10-05T14:15:51.450801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **RandomForestClassifier**","metadata":{}},{"cell_type":"code","source":"# K-Fold Cross-Validation với 5 folds\nkf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n    \n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}\\n')    \n\n    rf = RandomForestClassifier()\n    param_grid = {\n        'n_estimators': [100, 200, 300],  # Number of trees in the forest\n        'max_depth': [10, 20, 30],        # Maximum depth of the tree\n        'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n        'min_samples_leaf': [1, 2, 4]     # Minimum number of samples required at each leaf node\n    }\n\n    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n    \n    y_val_pred = grid_search.predict(X_val_fold)\n    y_val_pred_proba = grid_search.predict_proba(X_val_fold)\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss_fold_rf = log_loss(y_val_fold, y_val_pred_proba)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": rf,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss_fold_rf)\n\n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_rf = best_model.predict(X_test)\ny_pred_rf_proba = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\nrf = accuracy_score(y_test, y_pred_rf)\nconf_matrix = confusion_matrix(y_test, y_pred_rf)\nclass_report = classification_report(y_test, y_pred_rf)\nlogloss_rf = log_loss(y_test, y_pred_rf_proba)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {rf}\")\nprint(f\"LOGLOSS: {logloss_rf}\")\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_rf)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(logloss_all)\nprint(f\"Accucracy All : {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"Logloss All : {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:15:51.456607Z","iopub.execute_input":"2024-10-05T14:15:51.45741Z","iopub.status.idle":"2024-10-05T14:31:04.473569Z","shell.execute_reply.started":"2024-10-05T14:15:51.457327Z","shell.execute_reply":"2024-10-05T14:31:04.471393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GradientBoostingClassifier","metadata":{}},{"cell_type":"code","source":"kf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n\n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}\\n')    \n\n    gbm = GradientBoostingClassifier()\n    param_grid = {\n        'n_estimators': [100, 200, 300],  # Number of boosting stages to be run\n        'learning_rate': [0.01, 0.1, 0.2],  # Step size shrinkage\n        'max_depth': [3, 5, 7],          # Maximum depth of the tree\n        'min_samples_split': [2, 5, 10], # Minimum number of samples required to split a node\n        'min_samples_leaf': [1, 2, 4]    # Minimum number of samples required at each leaf node\n    }\n\n    grid_search = GridSearchCV(estimator=gbm, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n    \n    y_val_pred = grid_search.predict(X_val_fold)\n    y_val_pred_proba = grid_search.predict_proba(X_val_fold)\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss_fold_gb = log_loss(y_val_fold, y_val_pred_proba)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": gbm,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss_fold_gb)\n\n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_gb = best_model.predict(X_test)\ny_pred_gb_proba = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\ngb = accuracy_score(y_test, y_pred_gb)\nconf_matrix = confusion_matrix(y_test, y_pred_gb)\nclass_report = classification_report(y_test, y_pred_gb)\nlogloss_gb = log_loss(y_test, y_pred_gb_proba)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {gb}\")\nprint(f\"LOGLOSS: {logloss_gb}\")\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_gb)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(accuracy_all)\nprint(f\"Accucracy All : {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"Logloss All : {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:31:04.477095Z","iopub.execute_input":"2024-10-05T14:31:04.477875Z","iopub.status.idle":"2024-10-05T15:46:07.44255Z","shell.execute_reply.started":"2024-10-05T14:31:04.477796Z","shell.execute_reply":"2024-10-05T15:46:07.436781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVM","metadata":{}},{"cell_type":"code","source":"kf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n    \n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}\\n')    \n\n    svm = SVC(probability=True)\n    param_grid = {\n        'C': [0.1, 1, 10, 100],                # Điều chỉnh độ phạt sai số\n        'kernel': ['linear', 'rbf', 'poly'],    # Các loại kernel\n        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],  # Tham số gamma cho RBF, poly kernels\n        'degree': [2, 3, 4]                    # Bậc của polynomial kernel (nếu dùng 'poly')\n    }\n\n    grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n  \n    y_val_pred = grid_search.predict(X_val_fold)   \n    y_val_pred_proba = grid_search.predict(X_val_fold)\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss_fold_svm = log_loss(y_val_fold, y_val_pred_proba)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": gbm,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss_fold_svm)\n    \n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_svm = best_model.predict(X_test)\ny_pred_svm_proba = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\nsvm = accuracy_score(y_test, y_pred_svm)\nconf_matrix = confusion_matrix(y_test, y_pred_svm)\nclass_report = classification_report(y_test, y_pred_svm)\nlogloss_svm = log_loss(y_test, y_pred_svm_proba)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {svm}\")\nprint(f\"LOGLOSS: {logloss_svm}\")\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_svm)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(accuracy_all)\nprint(f\"Accucracy All : {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"Logloss All : {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T15:46:07.445454Z","iopub.execute_input":"2024-10-05T15:46:07.446807Z","iopub.status.idle":"2024-10-05T16:27:36.630498Z","shell.execute_reply.started":"2024-10-05T15:46:07.446722Z","shell.execute_reply":"2024-10-05T16:27:36.628077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = {\n    'Model': ['LR', 'LDA', 'KNN', 'CART', 'GNB', 'RF', 'AB','GB','SVM'],\n    'Accuracy': [lr, lda, knn, cart, gnb, rf, ab, gb, svm]\n}\n\n# Tạo DataFrame từ dữ liệu\ndf = pd.DataFrame(data)\n\n# Chuyển đổi cột 'Accuracy' thành kiểu số thực\ndf['Accuracy'] = df['Accuracy'].astype(float)\n\n# Vẽ biểu đồ barplot\nplt.figure(figsize=(10, 6))\nbarplot = sns.barplot(x='Model', y='Accuracy', data=df, palette='viridis')\nplt.title('Algorithm Comparison')\nplt.ylabel('Accuracy (Test)')\nplt.ylim(0, 1)  # Đặt giới hạn trục y từ 0 đến 1\n\n# Thêm thông số trên các cột\nfor p in barplot.patches:\n    barplot.annotate(f'{p.get_height():.2f}', \n                     (p.get_x() + p.get_width() / 2., p.get_height()), \n                     ha='center', va='bottom', \n                     fontsize=12)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T16:27:36.633619Z","iopub.execute_input":"2024-10-05T16:27:36.634629Z","iopub.status.idle":"2024-10-05T16:27:37.107523Z","shell.execute_reply.started":"2024-10-05T16:27:36.634542Z","shell.execute_reply":"2024-10-05T16:27:37.106149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc, roc_auc_score\n\ny = [y_pred_lr, y_pred_lda, y_pred_knn, y_pred_cart, y_pred_gnb, y_pred_rf, y_pred_ab, y_pred_gb, y_pred_svm]\nModel= ['LR', 'LDA', 'KNN', 'CART', 'GNB', 'RF', 'AB','GB','SVM']\ni = 0\n# Tính toán đường cong ROC và AUC\nfor y_pred in y:\n    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n    roc_auc = auc(fpr, tpr)\n\n    # Vẽ đường cong ROC\n    plt.figure(figsize=(6, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'Receiver Operating Characteristic (ROC) Curve {Model[i]}')\n    i = i + 1\n    plt.legend(loc=\"lower right\")\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T16:28:05.354764Z","iopub.execute_input":"2024-10-05T16:28:05.355333Z","iopub.status.idle":"2024-10-05T16:28:09.053439Z","shell.execute_reply.started":"2024-10-05T16:28:05.355281Z","shell.execute_reply":"2024-10-05T16:28:09.052101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = {\n    'Model': ['LR', 'LDA', 'KNN', 'CART', 'GNB', 'RF', 'AB','GB','SVM'],\n    'Logloss': [lr_logloss, logloss_lda, logloss_knn, logloss_cart, logloss_gnb, logloss_rf, logloss_ab, logloss_gb, logloss_svm]\n}\n\n# Tạo DataFrame từ dữ liệu\ndf = pd.DataFrame(data)\n\n# Chuyển đổi cột 'Accuracy' thành kiểu số thực\ndf['Logloss'] = df['Logloss'].astype(float)\n\n# Vẽ biểu đồ barplot\nplt.figure(figsize=(10, 6))\nbarplot = sns.barplot(x='Model', y='Logloss', data=df, palette='viridis')\nplt.title('Algorithm Comparison')\nplt.ylabel('Accuracy (Test)')\n\n# Thêm thông số trên các cột\nfor p in barplot.patches:\n    barplot.annotate(f'{p.get_height():.2f}', \n                     (p.get_x() + p.get_width() / 2., p.get_height()), \n                     ha='center', va='bottom', \n                     fontsize=12)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T16:30:02.636296Z","iopub.execute_input":"2024-10-05T16:30:02.636806Z","iopub.status.idle":"2024-10-05T16:30:03.128781Z","shell.execute_reply.started":"2024-10-05T16:30:02.636758Z","shell.execute_reply":"2024-10-05T16:30:03.127311Z"},"trusted":true},"execution_count":null,"outputs":[]}]}