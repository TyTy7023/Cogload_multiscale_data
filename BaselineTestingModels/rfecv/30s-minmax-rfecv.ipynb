{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":9448170,"datasetId":5720188,"databundleVersionId":9654618,"isSourceIdPinned":false}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **I/ setUpEnvironment**","metadata":{}},{"cell_type":"code","source":"#to access files and folders\nimport os\n#data analysis and manipulation library\nimport pandas as pd\n#math operations for multi-dimensional arrays and matrices\nimport numpy as np\n#visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set() #use a specific color theme\n\nimport warnings\nwarnings.simplefilter(\"ignore\")#ignore warnings during execution\n\n#Using model\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report, accuracy_score,log_loss\nfrom sklearn.metrics import confusion_matrix\n\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.svm import SVC","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-07T15:58:58.080865Z","iopub.execute_input":"2024-10-07T15:58:58.082193Z","iopub.status.idle":"2024-10-07T15:59:01.557798Z","shell.execute_reply.started":"2024-10-07T15:58:58.082131Z","shell.execute_reply":"2024-10-07T15:59:01.556452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **II/ readData**","metadata":{}},{"cell_type":"code","source":"#read the data\ndata_folder_path = '/kaggle/input/cognitiveload/UBIcomp2020/last_30s_segments/'\n#read the data\nprint('Reading data')\nlabel_df = pd.read_excel(data_folder_path+'labels.xlsx',index_col=0)\ntemp_df= pd.read_excel(data_folder_path+'temp.xlsx',index_col=0)\nhr_df= pd.read_excel(data_folder_path+'hr.xlsx',index_col=0)\ngsr_df = pd.read_excel(data_folder_path+'gsr.xlsx',index_col=0)\nrr_df= pd.read_excel(data_folder_path+'rr.xlsx',index_col=0)\nprint('Done')\n\n#check 30-second segments\nprint(\"Data shapes:\")\nprint('Labels',label_df.shape)\nprint('Temperature',temp_df.shape)\nprint('Heartrate',hr_df.shape)\nprint('GSR',gsr_df.shape)\nprint('RR',rr_df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-07T15:59:01.559904Z","iopub.execute_input":"2024-10-07T15:59:01.560660Z","iopub.status.idle":"2024-10-07T15:59:03.995298Z","shell.execute_reply.started":"2024-10-07T15:59:01.560604Z","shell.execute_reply":"2024-10-07T15:59:03.994055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **III/ SMA**","metadata":{}},{"cell_type":"code","source":"# window = 10\n# #apply moving average to each 30-second segment separately\n# temp_df = temp_df.rolling(window,axis=1).mean()\n# hr_df = hr_df.rolling(window,axis=1).mean()\n# gsr_df = gsr_df.rolling(window,axis=1).mean()\n# rr_df = rr_df.rolling(window,axis=1).mean()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **IV/ statisticalFeatures**","metadata":{}},{"cell_type":"code","source":"def extract_stat_features(df,data_type=''):\n  stat_features_names = ['mean','std','skew','kurtosis','diff','diff2','q25','q75','qdev','max-min']\n  final_names =  [data_type + '_' + x for x in stat_features_names]\n  features = pd.DataFrame(columns = stat_features_names) #create empty dataframe\n  values = [df.mean(axis=1).values, #mean\n            df.std(axis=1).values,  #standard deviation\n            df.skew(axis=1).values, #skewness\n            df.kurtosis(axis=1).values, #kurtosis\n            df.diff(axis=1).mean(axis=1).values, #mean value of first derivative\n            df.diff(axis=1).diff(axis=1).mean(axis=1).values, #mean value of second derivative\n            df.quantile(0.25,axis=1).values, #25th quantile\n            df.quantile(0.75,axis=1).values,#75th quantile\n            df.quantile(0.75,axis=1).values-df.quantile(0.25,axis=1).values, #quartile deviation\n            df.max(axis=1).values-df.min(axis=1).values] #range\n  values  = np.column_stack(values)\n  return pd.DataFrame(values,columns = final_names)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:11:45.502861Z","iopub.execute_input":"2024-10-05T14:11:45.503445Z","iopub.status.idle":"2024-10-05T14:11:45.515862Z","shell.execute_reply.started":"2024-10-05T14:11:45.503401Z","shell.execute_reply":"2024-10-05T14:11:45.514186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#extract features from heart-rate data\ntemp_stat_features = extract_stat_features(temp_df,'temp')\n\nhr_stat_features = extract_stat_features(hr_df,'hr')\n\ngsr_stat_features = extract_stat_features(gsr_df,'gsr')\n\nrr_stat_features = extract_stat_features(rr_df,'rr')\n\n#merge all statistical features into one table\nstat_feat_all = pd.concat([temp_stat_features,hr_stat_features,gsr_stat_features,rr_stat_features],axis=1)\nstat_feat_all","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:11:45.517912Z","iopub.execute_input":"2024-10-05T14:11:45.518498Z","iopub.status.idle":"2024-10-05T14:11:45.621729Z","shell.execute_reply.started":"2024-10-05T14:11:45.51844Z","shell.execute_reply":"2024-10-05T14:11:45.620281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids = ['3caqi','6frz4','bd47a','f1gjp','iz3x1']\n\ntrain_ids = ['1mpau', '2nxs5', '5gpsc', '7swyk', '8a1ep', 'b7mrd',\n       'c24ur', 'dkhty', 'e4gay', 'ef5rq', 'f3j25', 'hpbxa',\n       'ibvx8', 'iz2ps', 'rc1in', 'tn4vl', 'wjxci', 'yljm5']\n\nX_train = []\ny_train = []\nX_test = []\ny_test = []\nuser_train = []\nuser_test = []\n\nfor user in label_df.user_id.unique():\n    if user in train_ids:\n        user_features = stat_feat_all[label_df.user_id == user]\n        X_train.append(user_features)\n        y = label_df.loc[label_df.user_id == user, 'level'].values\n        \n        # Convert labels (rest,0,1,2) to binary (rest vs task)\n        y[y == 'rest'] = -1\n        y = y.astype(int) + 1\n        y[y > 0] = 1\n        y_train.extend(y)\n        \n        temp = label_df.loc[label_df.user_id==user,'user_id'].values #labels\n        user_train.extend(temp)\n    elif user in test_ids:\n        user_features = stat_feat_all[label_df.user_id == user]\n        X_test.append(user_features)\n        y = label_df.loc[label_df.user_id == user, 'level'].values\n        \n        # Convert labels (rest,0,1,2) to binary (rest vs task)\n        y[y == 'rest'] = -1\n        y = y.astype(int) + 1\n        y[y > 0] = 1\n        y_test.extend(y)\n        \n        temp = label_df.loc[label_df.user_id==user,'user_id'].values #labels\n        user_test.extend(temp)\n\n# Concatenate and convert to DataFrame/NumPy array\nX_train = pd.concat(X_train, ignore_index=True)\ny_train = np.array(y_train)\nX_test = pd.concat(X_test, ignore_index=True)\ny_test = np.array(y_test)\n\nprint('Train data:', X_train.shape, y_train.shape)\nprint('Test data:', X_test.shape, y_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:11:45.683406Z","iopub.execute_input":"2024-10-05T14:11:45.683877Z","iopub.status.idle":"2024-10-05T14:11:45.760301Z","shell.execute_reply.started":"2024-10-05T14:11:45.683834Z","shell.execute_reply":"2024-10-05T14:11:45.759009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **IV/ Preprocessing**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\nX_train = pd.DataFrame(X_train)\nX_test = pd.DataFrame(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:11:45.761826Z","iopub.execute_input":"2024-10-05T14:11:45.762266Z","iopub.status.idle":"2024-10-05T14:11:45.780301Z","shell.execute_reply.started":"2024-10-05T14:11:45.762227Z","shell.execute_reply":"2024-10-05T14:11:45.77893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **V/ featureSelection**","metadata":{}},{"cell_type":"code","source":"gk = GroupKFold(n_splits=len(np.unique(user_train)))\nsplits = gk.get_n_splits(X_train, y_train, user_train) #generate folds to evaluate the models using leave-one-subject-out\nestimator = XGBClassifier(n_jobs=-1)\nfs_clf = RFECV(estimator=estimator, #which estimator to use\n              step=1, #how many features to be removed at each iteration\n              cv=splits,#use pre-defined splits for evaluation (LOSO)\n              scoring='accuracy',\n              min_features_to_select=1,\n              n_jobs=-1)\n\nfs_clf.fit(X_train, y_train)#perform feature selection. Depending on the size of the data and the estimator, this may last for a while\nselected_features = X_train.columns[fs_clf.ranking_==1]\n\npred = fs_clf.predict(X_test)\n# print('Report for XGBClassifier with feature selection')\n# print(classification_report(y_test,pred))\n\nprint(\"Selected features:\", selected_features)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:11:45.819983Z","iopub.execute_input":"2024-10-05T14:11:45.820494Z","iopub.status.idle":"2024-10-05T14:12:58.497892Z","shell.execute_reply.started":"2024-10-05T14:11:45.820439Z","shell.execute_reply":"2024-10-05T14:12:58.496017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fs_train_orig = pd.DataFrame()\nfs_test_orig = pd.DataFrame()\ncolumns = X_train.columns\n\n# Thay đổi cách nối cột và tên cột\nfor i in selected_features:\n    # Thêm cột vào fs_train và fs_test với tên cột tương ứng\n    fs_train_orig[columns[i]] = X_train[columns[i]]\n    fs_test_orig[columns[i]] = X_test[columns[i]]\n    \nX_train = fs_train_orig\nX_test = fs_test_orig","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:12:58.499915Z","iopub.execute_input":"2024-10-05T14:12:58.500369Z","iopub.status.idle":"2024-10-05T14:12:58.535617Z","shell.execute_reply.started":"2024-10-05T14:12:58.500324Z","shell.execute_reply":"2024-10-05T14:12:58.534157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **VI/ Experiment**","metadata":{}},{"cell_type":"markdown","source":"# **Logistic Regession**","metadata":{}},{"cell_type":"code","source":"# K-Fold Cross-Validation với 6 folds\nkf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n    \n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}')    \n\n    logreg = LogisticRegression()\n    # Find best parmeter \n    param_grid = {\n        'C': [0.01, 0.1, 1, 10, 100],\n        'penalty': ['l1', 'l2'],        \n        'solver': ['liblinear']         \n    }\n    grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n    \n    y_val_pred = grid_search.predict(X_val_fold)\n    y_pred_prob = grid_search.predict_proba(X_val_fold)\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss = log_loss(y_val_fold, y_pred_prob)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": logreg,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss)\n\n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_lr = best_model.predict(X_test)\ny_pred_lr_proba = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\nlr = accuracy_score(y_test, y_pred_lr)\nconf_matrix = confusion_matrix(y_test, y_pred_lr)\nclass_report = classification_report(y_test, y_pred_lr)\nlr_logloss = log_loss(y_test, y_pred_lr_proba)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {lr}\")\nprint(f\"LOGLOSS: {lr_logloss}\")\n\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_lr)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(logloss_all)\nprint(f\"Accucracy all fold: {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"LogLoss all fold: {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:12:58.583714Z","iopub.execute_input":"2024-10-05T14:12:58.584246Z","iopub.status.idle":"2024-10-05T14:13:10.29496Z","shell.execute_reply.started":"2024-10-05T14:12:58.584182Z","shell.execute_reply":"2024-10-05T14:13:10.293822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **LDA**","metadata":{}},{"cell_type":"code","source":"# K-Fold Cross-Validation với 5 folds\nkf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n    \n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}')    \n\n    lda = LinearDiscriminantAnalysis()\n    param_grid = {\n        'solver': ['svd', 'lsqr', 'eigen'],  \n        'shrinkage': [None, 'auto', 0.1, 0.5, 0.9] \n    }\n    grid_search = GridSearchCV(estimator=lda, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n    \n    y_val_pred = grid_search.predict(X_val_fold)\n    y_pred_prob = grid_search.predict_proba(X_val_fold)\n\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss = log_loss(y_val_fold, y_pred_prob)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": lda,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss)\n    \n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_lda = best_model.predict(X_test)\ny_pred_lda_prob = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\nlda = accuracy_score(y_test, y_pred_lda)\nconf_matrix = confusion_matrix(y_test, y_pred_lda)\nclass_report = classification_report(y_test, y_pred_lda)\nlogloss_lda = log_loss(y_test, y_pred_lda_prob)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {lda}\")\nprint(f\"LOGLOSS: {logloss_lda}\")\n\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_lda)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(logloss_all)\nprint(f\"Accucracy All : {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"Logloss All : {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:13:10.317809Z","iopub.execute_input":"2024-10-05T14:13:10.319261Z","iopub.status.idle":"2024-10-05T14:13:13.120735Z","shell.execute_reply.started":"2024-10-05T14:13:10.319203Z","shell.execute_reply":"2024-10-05T14:13:13.119105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **knn**","metadata":{}},{"cell_type":"code","source":"# K-Fold Cross-Validation với 5 folds\nkf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n    \n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}\\n')    \n\n    knn = KNeighborsClassifier()\n    param_grid = {\n        'n_neighbors': [3, 5, 7, 9, 11],        # Số lượng láng giềng k\n        'weights': ['uniform', 'distance'],     # Trọng số: uniform (các điểm đều quan trọng), distance (trọng số theo khoảng cách)\n        'metric': ['euclidean', 'manhattan', 'minkowski']  # Loại khoảng cách: Euclidean, Manhattan hoặc Minkowski\n    }\n    grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n    \n    y_val_pred = grid_search.predict(X_val_fold)\n    y_val_pred_prob = grid_search.predict_proba(X_val_fold)\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss = log_loss(y_val_fold, y_val_pred_prob)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": knn,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss)\n\n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_knn = best_model.predict(X_test)\ny_pred_knn_proba = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\nknn = accuracy_score(y_test, y_pred_knn)\nconf_matrix = confusion_matrix(y_test, y_pred_knn)\nclass_report = classification_report(y_test, y_pred_knn)\nlogloss_knn = log_loss(y_test, y_pred_knn_proba)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {knn}\")\nprint(f\"LOGLOSS: {logloss_knn}\")\n\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_knn)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(logloss_all)\nprint(f\"Accucracy All : {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"Logloss All : {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:13:13.123794Z","iopub.execute_input":"2024-10-05T14:13:13.125207Z","iopub.status.idle":"2024-10-05T14:13:22.781415Z","shell.execute_reply.started":"2024-10-05T14:13:13.125123Z","shell.execute_reply":"2024-10-05T14:13:22.779904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **DecisionTreeClassifier**","metadata":{}},{"cell_type":"code","source":"# K-Fold Cross-Validation với 5 folds\nkf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n    \n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}\\n')    \n\n    cart = DecisionTreeClassifier()\n    param_grid = {\n        'criterion': ['gini', 'entropy'],   # Chỉ số phân chia: Gini hoặc Entropy\n        'max_depth': [None, 10, 20, 30, 40, 50],  # Chiều sâu tối đa của cây\n        'min_samples_split': [2, 10, 20],  # Số mẫu tối thiểu để chia nút\n        'min_samples_leaf': [1, 5, 10],    # Số mẫu tối thiểu tại mỗi nút lá\n        'max_features': [None, 'auto', 'sqrt', 'log2']  # Số lượng đặc trưng được xem xét tại mỗi nút phân chia\n    }\n\n    grid_search = GridSearchCV(estimator=cart, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n  \n    y_val_pred = grid_search.predict(X_val_fold)\n    y_val_pred_prob = grid_search.predict_proba(X_val_fold)\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss = log_loss(y_val_fold, y_val_pred_prob)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": cart,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss)\n\n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_cart = best_model.predict(X_test)\ny_pred_cart_proba = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\ncart = accuracy_score(y_test, y_pred_cart)\nconf_matrix = confusion_matrix(y_test, y_pred_cart)\nclass_report = classification_report(y_test, y_pred_cart)\nlogloss_cart = log_loss(y_test, y_pred_cart_proba)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {cart}\")\nprint(f\"LOGLOSS: {logloss_cart}\")\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_cart)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(logloss_all)\nprint(f\"Accucracy All : {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"Logloss All : {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:13:22.784342Z","iopub.execute_input":"2024-10-05T14:13:22.785505Z","iopub.status.idle":"2024-10-05T14:14:43.492728Z","shell.execute_reply.started":"2024-10-05T14:13:22.785428Z","shell.execute_reply":"2024-10-05T14:14:43.491083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **GaussianNB**","metadata":{}},{"cell_type":"code","source":"# K-Fold Cross-Validation với 5 folds\nkf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n    \n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}\\n')    \n\n    nb = GaussianNB()\n    param_grid = {\n        'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]  # Điều chỉnh biến nhỏ để tăng độ ổn định tính toán\n    }\n\n    grid_search = GridSearchCV(estimator=nb, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n  \n    y_val_pred = grid_search.predict(X_val_fold)\n    y_val_pred_proba = grid_search.predict_proba(X_val_fold)\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss = log_loss(y_val_fold, y_val_pred_proba)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": nb,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss)\n\n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_gnb = best_model.predict(X_test)\ny_pred_gnb_proba = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\ngnb = accuracy_score(y_test, y_pred_gnb)\nconf_matrix = confusion_matrix(y_test, y_pred_gnb)\nclass_report = classification_report(y_test, y_pred_gnb)\nlogloss_gnb = log_loss(y_test, y_pred_gnb_proba)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {gnb}\")\nprint(f\"LOGLOSS: {logloss_gnb}\")\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_gnb)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(logloss_all)\nprint(f\"Accucracy All : {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"Logloss All : {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:14:43.495676Z","iopub.execute_input":"2024-10-05T14:14:43.497217Z","iopub.status.idle":"2024-10-05T14:14:44.675653Z","shell.execute_reply.started":"2024-10-05T14:14:43.497123Z","shell.execute_reply":"2024-10-05T14:14:44.67385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **AdaBoots**","metadata":{}},{"cell_type":"code","source":"# K-Fold Cross-Validation với 5 folds\nkf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n    \n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}\\n')    \n\n    adaboost = AdaBoostClassifier()\n    param_grid = {\n        'n_estimators': [50, 100, 200],  # Số lượng bộ phân loại cơ sở (number of weak learners)\n        'learning_rate': [0.01, 0.1, 1.0],  # Tốc độ học (learning rate)\n    }\n\n    grid_search = GridSearchCV(estimator=adaboost, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n   \n    y_val_pred = grid_search.predict(X_val_fold)\n    y_val_pred_proba = grid_search.predict_proba(X_val_fold)\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss = log_loss(y_val_fold, y_val_pred_proba)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": adaboost,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss)\n\n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_ab = best_model.predict(X_test)\ny_pred_ab_proba = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\nab = accuracy_score(y_test, y_pred_ab)\nconf_matrix = confusion_matrix(y_test, y_pred_ab)\nclass_report = classification_report(y_test, y_pred_ab)\nlogloss_ab = log_loss(y_test, y_pred_ab_proba)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {ab}\")\nprint(f\"LOGLOSS: {logloss_ab}\")\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_ab)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(logloss_all)\nprint(f\"Accucracy All : {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"Logloss All : {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:14:44.678619Z","iopub.execute_input":"2024-10-05T14:14:44.679699Z","iopub.status.idle":"2024-10-05T14:15:51.453165Z","shell.execute_reply.started":"2024-10-05T14:14:44.679623Z","shell.execute_reply":"2024-10-05T14:15:51.450801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **RandomForestClassifier**","metadata":{}},{"cell_type":"code","source":"# K-Fold Cross-Validation với 5 folds\nkf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n    \n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}\\n')    \n\n    rf = RandomForestClassifier()\n    param_grid = {\n        'n_estimators': [100, 200, 300],  # Number of trees in the forest\n        'max_depth': [10, 20, 30],        # Maximum depth of the tree\n        'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n        'min_samples_leaf': [1, 2, 4]     # Minimum number of samples required at each leaf node\n    }\n\n    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n    \n    y_val_pred = grid_search.predict(X_val_fold)\n    y_val_pred_proba = grid_search.predict_proba(X_val_fold)\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss_fold_rf = log_loss(y_val_fold, y_val_pred_proba)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": rf,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss_fold_rf)\n\n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_rf = best_model.predict(X_test)\ny_pred_rf_proba = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\nrf = accuracy_score(y_test, y_pred_rf)\nconf_matrix = confusion_matrix(y_test, y_pred_rf)\nclass_report = classification_report(y_test, y_pred_rf)\nlogloss_rf = log_loss(y_test, y_pred_rf_proba)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {rf}\")\nprint(f\"LOGLOSS: {logloss_rf}\")\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_rf)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(logloss_all)\nprint(f\"Accucracy All : {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"Logloss All : {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:15:51.456607Z","iopub.execute_input":"2024-10-05T14:15:51.45741Z","iopub.status.idle":"2024-10-05T14:31:04.473569Z","shell.execute_reply.started":"2024-10-05T14:15:51.457327Z","shell.execute_reply":"2024-10-05T14:31:04.471393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GradientBoostingClassifier","metadata":{}},{"cell_type":"code","source":"kf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n\n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}\\n')    \n\n    gbm = GradientBoostingClassifier()\n    param_grid = {\n        'n_estimators': [100, 200, 300],  # Number of boosting stages to be run\n        'learning_rate': [0.01, 0.1, 0.2],  # Step size shrinkage\n        'max_depth': [3, 5, 7],          # Maximum depth of the tree\n        'min_samples_split': [2, 5, 10], # Minimum number of samples required to split a node\n        'min_samples_leaf': [1, 2, 4]    # Minimum number of samples required at each leaf node\n    }\n\n    grid_search = GridSearchCV(estimator=gbm, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n    \n    y_val_pred = grid_search.predict(X_val_fold)\n    y_val_pred_proba = grid_search.predict_proba(X_val_fold)\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss_fold_gb = log_loss(y_val_fold, y_val_pred_proba)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": gbm,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss_fold_gb)\n\n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_gb = best_model.predict(X_test)\ny_pred_gb_proba = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\ngb = accuracy_score(y_test, y_pred_gb)\nconf_matrix = confusion_matrix(y_test, y_pred_gb)\nclass_report = classification_report(y_test, y_pred_gb)\nlogloss_gb = log_loss(y_test, y_pred_gb_proba)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {gb}\")\nprint(f\"LOGLOSS: {logloss_gb}\")\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_gb)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(accuracy_all)\nprint(f\"Accucracy All : {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"Logloss All : {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T14:31:04.477095Z","iopub.execute_input":"2024-10-05T14:31:04.477875Z","iopub.status.idle":"2024-10-05T15:46:07.44255Z","shell.execute_reply.started":"2024-10-05T14:31:04.477796Z","shell.execute_reply":"2024-10-05T15:46:07.436781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVM","metadata":{}},{"cell_type":"code","source":"kf = GroupKFold(n_splits=6)\n\nbest_model = None\nbest_score = 0\nfold_results = []\naccuracy_all = []\nlogloss_all = []\n\n# Lặp qua từng fold\nfor fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train, groups = user_train)):\n    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n    \n    id_user = np.array(user_train)\n    # Kiểm tra nhóm trong fold\n    train_groups = id_user[train_index]\n    val_groups = id_user[val_index]\n    \n    print(f'User of train_fold({fold}) : {np.unique(train_groups)}')\n    print(f'User of val_fold({fold}) :{np.unique(val_groups)}\\n')    \n\n    svm = SVC(probability=True)\n    param_grid = {\n        'C': [0.1, 1, 10, 100],                # Điều chỉnh độ phạt sai số\n        'kernel': ['linear', 'rbf', 'poly'],    # Các loại kernel\n        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],  # Tham số gamma cho RBF, poly kernels\n        'degree': [2, 3, 4]                    # Bậc của polynomial kernel (nếu dùng 'poly')\n    }\n\n    grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=GroupKFold(n_splits=3), scoring='accuracy', verbose=1)\n    grid_search.fit(X_train_fold, y_train_fold, groups = train_groups)\n    print(f\"Best parameters found: {grid_search.best_params_}\\n\" )\n  \n    y_val_pred = grid_search.predict(X_val_fold)   \n    y_val_pred_proba = grid_search.predict(X_val_fold)\n\n    accuracy = accuracy_score(y_val_fold, y_val_pred)\n    conf_matrix = confusion_matrix(y_val_fold, y_val_pred)\n    class_report = classification_report(y_val_fold, y_val_pred)\n    logloss_fold_svm = log_loss(y_val_fold, y_val_pred_proba)\n\n    fold_results.append({\n        \"fold\": fold,\n        \"model\": gbm,\n        \"accuracy\": accuracy,\n        \"confusion_matrix\": conf_matrix,\n        \"classification_report\": class_report\n        })\n    accuracy_all.append(accuracy)\n    logloss_all.append(logloss_fold_svm)\n    \n    if accuracy > best_score:\n        best_score = accuracy\n        best_model = grid_search\n\n# Dự đoán trên tập kiểm tra\ny_pred_svm = best_model.predict(X_test)\ny_pred_svm_proba = best_model.predict_proba(X_test)\n\n# Đánh giá mô hình trên tập kiểm tra\nsvm = accuracy_score(y_test, y_pred_svm)\nconf_matrix = confusion_matrix(y_test, y_pred_svm)\nclass_report = classification_report(y_test, y_pred_svm)\nlogloss_svm = log_loss(y_test, y_pred_svm_proba)\n\nprint(\"Report:\" + class_report)\nprint(f\"ACCURACY: {svm}\")\nprint(f\"LOGLOSS: {logloss_svm}\")\n\n# Xác định các lớp để hiển thị trong ma trận nhầm lẫn\nunique_labels = np.unique(np.concatenate((y_test, y_pred_svm)))\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, \n            xticklabels=unique_labels.tolist(), \n            yticklabels=unique_labels.tolist())\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\naccuracy_all = np.array(accuracy_all)\nlogloss_all = np.array(accuracy_all)\nprint(f\"Accucracy All : {accuracy_all}\\nMean: {accuracy_all.mean()} ---- Std: {accuracy_all.std()}\")\nprint(f\"Logloss All : {logloss_all}\\nMean: {logloss_all.mean()} ---- Std: {logloss_all.std()}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T15:46:07.445454Z","iopub.execute_input":"2024-10-05T15:46:07.446807Z","iopub.status.idle":"2024-10-05T16:27:36.630498Z","shell.execute_reply.started":"2024-10-05T15:46:07.446722Z","shell.execute_reply":"2024-10-05T16:27:36.628077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = {\n    'Model': ['LR', 'LDA', 'KNN', 'CART', 'GNB', 'RF', 'AB','GB','SVM'],\n    'Accuracy': [lr, lda, knn, cart, gnb, rf, ab, gb, svm]\n}\n\n# Tạo DataFrame từ dữ liệu\ndf = pd.DataFrame(data)\n\n# Chuyển đổi cột 'Accuracy' thành kiểu số thực\ndf['Accuracy'] = df['Accuracy'].astype(float)\n\n# Vẽ biểu đồ barplot\nplt.figure(figsize=(10, 6))\nbarplot = sns.barplot(x='Model', y='Accuracy', data=df, palette='viridis')\nplt.title('Algorithm Comparison')\nplt.ylabel('Accuracy (Test)')\nplt.ylim(0, 1)  # Đặt giới hạn trục y từ 0 đến 1\n\n# Thêm thông số trên các cột\nfor p in barplot.patches:\n    barplot.annotate(f'{p.get_height():.2f}', \n                     (p.get_x() + p.get_width() / 2., p.get_height()), \n                     ha='center', va='bottom', \n                     fontsize=12)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T16:27:36.633619Z","iopub.execute_input":"2024-10-05T16:27:36.634629Z","iopub.status.idle":"2024-10-05T16:27:37.107523Z","shell.execute_reply.started":"2024-10-05T16:27:36.634542Z","shell.execute_reply":"2024-10-05T16:27:37.106149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc, roc_auc_score\n\ny = [y_pred_lr, y_pred_lda, y_pred_knn, y_pred_cart, y_pred_gnb, y_pred_rf, y_pred_ab, y_pred_gb, y_pred_svm]\nModel= ['LR', 'LDA', 'KNN', 'CART', 'GNB', 'RF', 'AB','GB','SVM']\ni = 0\n# Tính toán đường cong ROC và AUC\nfor y_pred in y:\n    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n    roc_auc = auc(fpr, tpr)\n\n    # Vẽ đường cong ROC\n    plt.figure(figsize=(6, 6))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'Receiver Operating Characteristic (ROC) Curve {Model[i]}')\n    i = i + 1\n    plt.legend(loc=\"lower right\")\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T16:28:05.354764Z","iopub.execute_input":"2024-10-05T16:28:05.355333Z","iopub.status.idle":"2024-10-05T16:28:09.053439Z","shell.execute_reply.started":"2024-10-05T16:28:05.355281Z","shell.execute_reply":"2024-10-05T16:28:09.052101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = {\n    'Model': ['LR', 'LDA', 'KNN', 'CART', 'GNB', 'RF', 'AB','GB','SVM'],\n    'Logloss': [lr_logloss, logloss_lda, logloss_knn, logloss_cart, logloss_gnb, logloss_rf, logloss_ab, logloss_gb, logloss_svm]\n}\n\n# Tạo DataFrame từ dữ liệu\ndf = pd.DataFrame(data)\n\n# Chuyển đổi cột 'Accuracy' thành kiểu số thực\ndf['Logloss'] = df['Logloss'].astype(float)\n\n# Vẽ biểu đồ barplot\nplt.figure(figsize=(10, 6))\nbarplot = sns.barplot(x='Model', y='Logloss', data=df, palette='viridis')\nplt.title('Algorithm Comparison')\nplt.ylabel('Accuracy (Test)')\n\n# Thêm thông số trên các cột\nfor p in barplot.patches:\n    barplot.annotate(f'{p.get_height():.2f}', \n                     (p.get_x() + p.get_width() / 2., p.get_height()), \n                     ha='center', va='bottom', \n                     fontsize=12)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T16:30:02.636296Z","iopub.execute_input":"2024-10-05T16:30:02.636806Z","iopub.status.idle":"2024-10-05T16:30:03.128781Z","shell.execute_reply.started":"2024-10-05T16:30:02.636758Z","shell.execute_reply":"2024-10-05T16:30:03.127311Z"},"trusted":true},"execution_count":null,"outputs":[]}]}